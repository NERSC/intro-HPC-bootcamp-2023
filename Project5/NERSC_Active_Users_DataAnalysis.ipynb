{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96af348-7772-42f8-838e-a0ed2c8595d4",
   "metadata": {},
   "source": [
    "# Analyzing NERSC User Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ddaa4-34c4-4742-a362-93e80746c91b",
   "metadata": {},
   "source": [
    "First, we will need to load the necessary data to load a CSV file into a pandas DataFrame\n",
    "in a Python environment, you use the pd.read_csv() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315eb6f-0847-480c-bf31-87e7829ef01b",
   "metadata": {},
   "source": [
    "In the data_path, you should replace \"/path/to/your/data/NERSC_User_Data.csv\" \n",
    "with the actual path to your CSV file.  After running this command, the data from the CSV file \n",
    "will be loaded into the `pandas` DataFrame `df`, and the first five rows of the DataFrame will be printed out.\n",
    "This is typically the first step in analyzing data with pandas in a Python environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a493f-6a17-4cbb-81f6-84cc728473b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the data file path\n",
    "\n",
    "#data_path = \"/path/to/your/data/NERSC_active_users_20230627.csv\"\n",
    "data_path = \"data/NERSC_User_Data.csv\"\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe5527-2114-4810-ba2e-85321f6e234f",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb73fa61-8fab-47a9-892c-cfd99abeb800",
   "metadata": {},
   "source": [
    "One of the first parts of exploratory data analysis is looking at the metadata. This mean looking at the size of the data (rows and columns), as well as the data types. Let's start looking at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedd6f8-57e0-4f26-b5ca-31b977ffd852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of rows and columns in the DataFrame\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Column names\n",
    "print(f\"Column names: {df.columns.tolist()}\")\n",
    "\n",
    "# Data types of the columns\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd95762-b968-4205-b639-904748a2cdb8",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9232d7-6d32-4d44-af6d-895cad870c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can use the `.astype()` function defined on the DataFrame object, to cast a column of one type to another. Let's try it! For example, the CPU Compute Allocation (which is the number of compute hours that user has in their account) is a floating point number, but since the allocation is usually given in whole hours, we can try converting the values in this column into integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e85e86-4afb-4df3-8846-ad06a0a61117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Your Code Here:\n",
    "#df[\"CPU Compute Allocation\"].astype('what goes here?')\n",
    "#Solution: \n",
    "df[\"CPU Compute Allocation\"].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2a21a-6c90-4773-a0b7-3adf954b8b6d",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fd4fd-6ca4-4cca-975d-10fe45d557d9",
   "metadata": {},
   "source": [
    "The Pandas library has a lot of convenient functions available for quick statistics on numerical data. Notice that only numerical columns are considered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333799a-237a-4a3d-a4a8-c15952e6a0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dd882-96d0-47c4-a596-91b814b0862d",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e190158-abe8-482a-b9ab-40d545a15ed2",
   "metadata": {},
   "source": [
    "Finally, we can create some basic visualizations. \n",
    "We can create a histogram for the 'CPU Compute Allocation' column to understand its distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd845ac-072a-4ec1-9c98-177ce2cb1aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Histogram for 'CPU Compute Allocation'\n",
    "plt.hist(df['CPU Compute Allocation'], bins=100, edgecolor='black')\n",
    "plt.xlabel('CPU Compute Allocation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of CPU Compute Allocation')\n",
    "#plt.xlim([np.min(df['CPU Compute Allocation']), 0.01*np.max(df['CPU Compute Allocation'])])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(df['GPU Compute Allocation'], bins=1000, edgecolor='black')\n",
    "plt.xlabel('GPU Compute Allocation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of GPU Compute Allocation')\n",
    "#plt.xlim([np.min(df['GPU Compute Allocation']), 0.01*np.max(df['GPU Compute Allocation'])])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce761a-4024-4cbf-9462-ab996b928b87",
   "metadata": {},
   "source": [
    "For categorical data, we can use bar plots. \n",
    "For instance, we can plot the number of active users per organization type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772c6c6-780c-4b1f-9149-9e18b0e13821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count of active users per 'Organization Type'\n",
    "org_type_counts = df[df['Is Active'] == True]['Organization Type'].value_counts()\n",
    "\n",
    "# Bar plot\n",
    "org_type_counts.plot(kind='bar', edgecolor='black')\n",
    "plt.xlabel('Organization Type')\n",
    "plt.ylabel('Number of Active Users')\n",
    "plt.title('Number of Active Users per Organization Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f66160-b83d-4745-99f3-489bb20a74c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Please note that, before running the visualization code, \n",
    "make sure the relevant packages (matplotlib in this case) are installed in your environment. \n",
    "If not, you can install it using the command !pip install matplotlib in a new cell. \n",
    "If you're running this on a local environment, you may need to remove the !."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f719a13-44ae-466a-add1-8880665d250e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count of active users per 'Organization Type'\n",
    "org_type_counts = df[df['Is Active'] == True]['PI Name'].value_counts()\n",
    "\n",
    "# Bar plot\n",
    "org_type_counts.plot(kind='bar', edgecolor='black')\n",
    "plt.xlabel('Organization Type')\n",
    "plt.ylabel('Number of Active Users')\n",
    "plt.title('Number of Active Users per Organization Type')\n",
    "plt.xlim([-0.5,9.5])\n",
    "plt.show()\n",
    "## just look at a few?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c61fdf-6398-4e27-bec3-73967409fd41",
   "metadata": {},
   "source": [
    "The following cell will isolate the data from only the top 10 PIs at NERSC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090c64b-4e87-4da7-a2c8-90832dcaa55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topusers = df.groupby(\"PI Name\").count()\n",
    "toppis = list(topusers.sort_values(\"Organization\", ascending = False).index[:10])\n",
    "top10data = df.loc[df['PI Name'].isin(toppis)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d7296-fa86-4982-86cd-fd0b9a6684b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top10data[\"PI Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab627b-7014-4618-8e64-1f92155fff69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "account_path = \"/pscratch/sd/l/lgupta/IntroToHPC/UserData/PI_acct.json\"\n",
    "with open(account_path, 'r') as j:\n",
    "     account_info = json.loads(j.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875248e-39b1-491a-9c5f-280f6734a867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "account_info[\"Stephen Bailey\"][\"account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ebb40-d89b-4c1f-b3b3-aec561cc7e56",
   "metadata": {},
   "source": [
    "Exercise and set-up left to do: \n",
    "\n",
    "\n",
    "    - Use Jinja2 to make sacct template and populate with account info\n",
    "    - Run scripts on PM\n",
    "    - look at the power consumption. \n",
    "    - normalize by the number of active users\n",
    "    - look at which ones are actually using the most energy at NERSC\n",
    "    - thats why having optimized code is important "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952aeceb-17a4-4257-88b1-3a9fc3802d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
